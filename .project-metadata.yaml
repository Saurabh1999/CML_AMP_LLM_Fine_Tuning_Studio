name: CML Fine Tuning Studio
description: |
  This AMP demonstrates how PEFT and other fine-tuning optimization techniques can be used for efficient and effective customization of an existing LLM to perform new tasks.
author: Cloudera Inc.
specification_version: 1.0
prototype_version: 1.0
date: "2023-07-22"

environment_variables:
  FINE_TUNING_APP_STATE_LOCATION:
    default: ".app/state.json"
    description: >-
      The location of the FT app's state, which is a session store that saves app information across browser sessions.
  CUSTOM_LORA_ADAPTERS_DIR:
    default: "data/adapters/"
    description: >-
      The directory containing the reproduced LoRA adapters created by the fine-tuning jobs in this project. Also the location to look for any custom LoRA adapters.
  HUGGINGFACE_ACCESS_TOKEN:
    default: ""
    description: >-
      In order to access Huggingface gated models, please create a Huggingface Access Token. Log in to Huggingface -> Settings -> Access Tokens.

runtimes:
  - editor: PBJ Workbench
    kernel: Python 3.9
    edition: Nvidia GPU

tasks:
  # - type: run_session
  #   name: Validate GPU Availibility in this workspace
  #   script: bin/check_gpu_resources.py
  #   short_summary: Check for GPU availibility. 
  #   long_summary: Check GPUs are enabled on this workspace and are currently schedulable.
  #   kernel: python3
  #   cpu: 2
  #   memory: 4

  - type: run_session
    name: Install Dependencies
    script: bin/install-dependencies.py
    short_summary: Install Dependencies
    kernel: python3
    cpu: 2
    memory: 8
  
  # - type: run_session
  #   name: Validate GPU CUDA Capability
  #   script: bin/check_gpu_capability.py
  #   short_summary: Check for GPU capability. 
  #   long_summary: Check GPU device supports the CUDA capabilities required.
  #   kernel: python3
  #   cpu: 2
  #   memory: 4
  #   gpu: 1

  - type: create_job
    name: Finetuning_Base_Jobs
    short_summary: Create Template Job for creating finetuning tasks
    entity_label: fine_tune_job_template
    script: ft/scripts/fine_tune_base_script.py
    arguments: None
    long_summary: Create Template Job for creating finetuning tasks. This job is used as the template for creating and launching fine-tuning tasks in the application.
    cpu: 2
    memory: 8
    gpu: 1
    environment:
      TASK_TYPE: CREATE/RUN_JOB
      MLFLOW_FLATTEN_PARAMS: true

  - type: create_job
    name: Mlflow_Evaluation_Base_Job
    short_summary: Create Template Job for creating mlflow evaluation tasks
    entity_label: mlflow_evaluation_job_template
    script: ft/scripts/mlflow_evaluation_base_script.py
    arguments: None
    long_summary: Create Template Job for creating mlflow evaluation tasks. This job is used as the template for creating and launching mlflow evaluation tasks in the application.
    cpu: 2
    memory: 8
    gpu: 1
    environment:
      TASK_TYPE: CREATE/RUN_JOB
  
  - type: start_application
    name: CML Fine Tuning Studio
    subdomain: cml-llm-fine-tuning-studio
    script: bin/run-app.py
    long_summary: This application requires an available GPU to run the LLM model and LoRA adapters.
    cpu: 2
    memory: 8
    gpu: 1
    environment_variables:
      TASK_TYPE: START_APPLICATION
